"""
GPU-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RTX 4060
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, f_classif
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
import joblib
import os
import warnings
import time
warnings.filterwarnings('ignore')

def check_gpu_availability():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU"""
    print("üîç –ü–†–û–í–ï–†–ö–ê GPU")
    print("=" * 25)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º CUDA
    try:
        import cupy as cp
        print(f"‚úÖ CuPy –¥–æ—Å—Ç—É–ø–µ–Ω")
        print(f"   CUDA –≤–µ—Ä—Å–∏—è: {cp.cuda.runtime.runtimeGetVersion()}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {cp.cuda.runtime.getDeviceCount()}")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
        for i in range(cp.cuda.runtime.getDeviceCount()):
            props = cp.cuda.runtime.getDeviceProperties(i)
            print(f"   GPU {i}: {props['name'].decode()}")
            print(f"   –ü–∞–º—è—Ç—å: {props['totalGlobalMem'] / 1024**3:.1f} GB")
        
        return True
    except Exception as e:
        print(f"‚ùå CuPy –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return False

def load_and_analyze_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
    print("\nüìä –ó–ê–ì–†–£–ó–ö–ê –ò –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv('../../data/raw/wine_quality.csv')
    
    print(f"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape}")
    print(f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
    print(f"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {df.isnull().sum().sum()}")
    print(f"–î—É–±–ª–∏–∫–∞—Ç—ã: {df.duplicated().sum()}")
    
    # –ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    print(f"\nüéØ –¶–ï–õ–ï–í–ê–Ø –ü–ï–†–ï–ú–ï–ù–ù–ê–Ø (quality)")
    print("=" * 30)
    print(df['quality'].value_counts().sort_index())
    print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ: {df['quality'].mean():.2f}")
    print(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {df['quality'].std():.2f}")
    
    return df

def advanced_preprocessing(df):
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîß –ü–†–û–î–í–ò–ù–£–¢–ê–Ø –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê")
    print("=" * 40)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö
    df_processed = df.copy()
    
    # 1. –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    initial_size = len(df_processed)
    df_processed = df_processed.drop_duplicates()
    print(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {initial_size - len(df_processed)}")
    
    # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é IQR
    numeric_columns = df_processed.select_dtypes(include=[np.number]).columns
    outliers_removed = 0
    
    for col in numeric_columns:
        if col != 'quality':  # –ù–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            Q1 = df_processed[col].quantile(0.25)
            Q3 = df_processed[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = ((df_processed[col] < lower_bound) | (df_processed[col] > upper_bound)).sum()
            outliers_removed += outliers
            
            # –£–¥–∞–ª—è–µ–º –≤—ã–±—Ä–æ—Å—ã
            df_processed = df_processed[(df_processed[col] >= lower_bound) & (df_processed[col] <= upper_bound)]
    
    print(f"–£–¥–∞–ª–µ–Ω–æ –≤—ã–±—Ä–æ—Å–æ–≤: {outliers_removed}")
    print(f"–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {df_processed.shape}")
    
    # 3. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
    df_processed['acid_ratio'] = df_processed['fixed.acidity'] / (df_processed['volatile.acidity'] + 1e-8)
    df_processed['sulfur_ratio'] = df_processed['free.sulfur.dioxide'] / (df_processed['total.sulfur.dioxide'] + 1e-8)
    df_processed['alcohol_density_ratio'] = df_processed['alcohol'] / df_processed['density']
    
    # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
    df_processed['log_residual_sugar'] = np.log1p(df_processed['residual.sugar'])
    df_processed['log_chlorides'] = np.log1p(df_processed['chlorides'])
    
    # –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df_processed['alcohol_squared'] = df_processed['alcohol'] ** 2
    df_processed['ph_squared'] = df_processed['pH'] ** 2
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∞–ª–∫–æ–≥–æ–ª—è
    df_processed['alcohol_category'] = pd.cut(df_processed['alcohol'], 
                                            bins=[0, 10, 12, 15], 
                                            labels=['low', 'medium', 'high'])
    
    # One-hot encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    df_processed = pd.get_dummies(df_processed, columns=['alcohol_category'], prefix='alcohol')
    
    print(f"–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ feature engineering: {df_processed.shape}")
    
    return df_processed

def feature_selection(X, y):
    """–û—Ç–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print("\nüéØ –û–¢–ë–û–† –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 25)
    
    # 1. Univariate feature selection
    selector_univariate = SelectKBest(score_func=f_classif, k=20)
    X_selected = selector_univariate.fit_transform(X, y)
    selected_features = X.columns[selector_univariate.get_support()]
    print(f"–û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (univariate): {len(selected_features)}")
    print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏: {list(selected_features)}")
    
    return X_selected, selected_features

def train_gpu_models(X_train, X_test, y_train, y_test):
    """–û–±—É—á–µ–Ω–∏–µ GPU-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    print("\nüöÄ –û–ë–£–ß–ï–ù–ò–ï GPU-–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–• –ú–û–î–ï–õ–ï–ô")
    print("=" * 55)
    
    models = {}
    training_times = {}
    
    # 1. XGBoost —Å GPU
    print("1. XGBoost (GPU)...")
    start_time = time.time()
    
    xgb_params = {
        'n_estimators': [500, 1000, 1500],
        'max_depth': [6, 8, 10],
        'learning_rate': [0.05, 0.1, 0.15],
        'subsample': [0.8, 0.9, 1.0],
        'colsample_bytree': [0.8, 0.9, 1.0],
        'tree_method': ['gpu_hist'],
        'gpu_id': [0],
        'random_state': [42]
    }
    
    xgb_model = xgb.XGBClassifier(
        tree_method='gpu_hist',
        gpu_id=0,
        random_state=42,
        eval_metric='mlogloss'
    )
    
    xgb_grid = GridSearchCV(
        xgb_model, 
        xgb_params, 
        cv=5, 
        scoring='f1_weighted', 
        n_jobs=1,  # GPU –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º
        verbose=1
    )
    
    xgb_grid.fit(X_train, y_train)
    models['XGBoost_GPU'] = xgb_grid.best_estimator_
    training_times['XGBoost_GPU'] = time.time() - start_time
    
    print(f"   –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {xgb_grid.best_params_}")
    print(f"   –õ—É—á—à–∏–π score: {xgb_grid.best_score_:.4f}")
    print(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_times['XGBoost_GPU']:.2f} —Å–µ–∫")
    
    # 2. LightGBM —Å GPU
    print("2. LightGBM (GPU)...")
    start_time = time.time()
    
    lgb_params = {
        'n_estimators': [500, 1000, 1500],
        'max_depth': [6, 8, 10],
        'learning_rate': [0.05, 0.1, 0.15],
        'subsample': [0.8, 0.9, 1.0],
        'colsample_bytree': [0.8, 0.9, 1.0],
        'device': ['gpu'],
        'random_state': [42]
    }
    
    lgb_model = lgb.LGBMClassifier(
        device='gpu',
        random_state=42,
        verbose=-1
    )
    
    lgb_grid = GridSearchCV(
        lgb_model, 
        lgb_params, 
        cv=5, 
        scoring='f1_weighted', 
        n_jobs=1,
        verbose=1
    )
    
    lgb_grid.fit(X_train, y_train)
    models['LightGBM_GPU'] = lgb_grid.best_estimator_
    training_times['LightGBM_GPU'] = time.time() - start_time
    
    print(f"   –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {lgb_grid.best_params_}")
    print(f"   –õ—É—á—à–∏–π score: {lgb_grid.best_score_:.4f}")
    print(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_times['LightGBM_GPU']:.2f} —Å–µ–∫")
    
    # 3. CatBoost —Å GPU
    print("3. CatBoost (GPU)...")
    start_time = time.time()
    
    catboost_params = {
        'iterations': [500, 1000, 1500],
        'depth': [6, 8, 10],
        'learning_rate': [0.05, 0.1, 0.15],
        'task_type': ['GPU'],
        'devices': ['0'],
        'random_seed': [42]
    }
    
    catboost_model = CatBoostClassifier(
        task_type='GPU',
        devices='0',
        random_seed=42,
        verbose=False
    )
    
    catboost_grid = GridSearchCV(
        catboost_model, 
        catboost_params, 
        cv=5, 
        scoring='f1_weighted', 
        n_jobs=1,
        verbose=1
    )
    
    catboost_grid.fit(X_train, y_train)
    models['CatBoost_GPU'] = catboost_grid.best_estimator_
    training_times['CatBoost_GPU'] = time.time() - start_time
    
    print(f"   –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {catboost_grid.best_params_}")
    print(f"   –õ—É—á—à–∏–π score: {catboost_grid.best_score_:.4f}")
    print(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_times['CatBoost_GPU']:.2f} —Å–µ–∫")
    
    # 4. CPU –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    print("4. Random Forest (CPU) –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è...")
    start_time = time.time()
    
    rf_params = {
        'n_estimators': [200, 300, 500],
        'max_depth': [15, 20, 25, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2']
    }
    
    rf = RandomForestClassifier(random_state=42, n_jobs=-1)
    rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1)
    rf_grid.fit(X_train, y_train)
    models['RandomForest_CPU'] = rf_grid.best_estimator_
    training_times['RandomForest_CPU'] = time.time() - start_time
    
    print(f"   –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {rf_grid.best_params_}")
    print(f"   –õ—É—á—à–∏–π score: {rf_grid.best_score_:.4f}")
    print(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_times['RandomForest_CPU']:.2f} —Å–µ–∫")
    
    return models, training_times

def evaluate_models(models, X_test, y_test, training_times):
    """–û—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
    print("\nüìä –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô")
    print("=" * 30)
    
    results = {}
    
    for name, model in models.items():
        print(f"\n{name}:")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        start_time = time.time()
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)
        prediction_time = time.time() - start_time
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='weighted')
        
        results[name] = {
            'accuracy': accuracy,
            'f1_score': f1,
            'predictions': y_pred,
            'probabilities': y_pred_proba,
            'training_time': training_times[name],
            'prediction_time': prediction_time
        }
        
        print(f"   Accuracy: {accuracy:.4f}")
        print(f"   F1-score: {f1:.4f}")
        print(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_times[name]:.2f} —Å–µ–∫")
        print(f"   –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {prediction_time:.4f} —Å–µ–∫")
        
        # Cross-validation
        cv_scores = cross_val_score(model, X_test, y_test, cv=5, scoring='f1_weighted')
        print(f"   CV F1-score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
    
    return results

def save_best_model(models, results, selected_features):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å"""
    print("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò")
    print("=" * 35)
    
    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ F1-score
    best_model_name = max(results.keys(), key=lambda x: results[x]['f1_score'])
    best_model = models[best_model_name]
    best_score = results[best_model_name]['f1_score']
    
    print(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
    print(f"F1-score: {best_score:.4f}")
    print(f"Accuracy: {results[best_model_name]['accuracy']:.4f}")
    print(f"–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {results[best_model_name]['training_time']:.2f} —Å–µ–∫")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    os.makedirs('../../models', exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_path = '../../models/wine_quality_gpu_model.pkl'
    joblib.dump(best_model, model_path)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
    features_path = '../../models/gpu_selected_features.pkl'
    joblib.dump(selected_features, features_path)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics_path = '../../models/gpu_model_metrics.txt'
    with open(metrics_path, 'w') as f:
        f.write(f"GPU Wine Quality Model\n")
        f.write(f"Best Model: {best_model_name}\n")
        f.write(f"F1-score: {best_score:.4f}\n")
        f.write(f"Accuracy: {results[best_model_name]['accuracy']:.4f}\n")
        f.write(f"Training Time: {results[best_model_name]['training_time']:.2f} —Å–µ–∫\n")
        f.write(f"Prediction Time: {results[best_model_name]['prediction_time']:.4f} —Å–µ–∫\n")
        f.write(f"Selected Features: {len(selected_features)}\n")
        f.write(f"Features: {list(selected_features)}\n")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        f.write(f"\n–í—Å–µ –º–æ–¥–µ–ª–∏:\n")
        for name, result in results.items():
            f.write(f"{name}: F1={result['f1_score']:.4f}, Acc={result['accuracy']:.4f}, Time={result['training_time']:.2f}s\n")
    
    print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_path}")
    print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {features_path}")
    print(f"–ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {metrics_path}")
    
    return best_model_name, best_model

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ GPU-–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ö–ê–ß–ï–°–¢–í–ê –í–ò–ù–ê")
    print("=" * 70)
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
    gpu_available = check_gpu_availability()
    if not gpu_available:
        print("‚ö†Ô∏è  GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏–º —Å CPU –≤–µ—Ä—Å–∏—è–º–∏")
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
    df = load_and_analyze_data()
    
    # 3. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    df_processed = advanced_preprocessing(df)
    
    # 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = df_processed.drop('quality', axis=1)
    y = df_processed['quality']
    
    # 5. –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    X_selected, selected_features = feature_selection(X, y)
    
    # 6. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(
        X_selected, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\nüìä –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•")
    print("=" * 25)
    print(f"Train set: {X_train.shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"Test set: {X_test.shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"–ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train.shape[1]}")
    
    # 7. –û–±—É—á–µ–Ω–∏–µ GPU –º–æ–¥–µ–ª–µ–π
    models, training_times = train_gpu_models(X_train, X_test, y_train, y_test)
    
    # 8. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
    results = evaluate_models(models, X_test, y_test, training_times)
    
    # 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model_name, best_model = save_best_model(models, results, selected_features)
    
    print(f"\nüéâ GPU –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 40)
    print(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
    print(f"F1-score: {results[best_model_name]['f1_score']:.4f}")
    print(f"Accuracy: {results[best_model_name]['accuracy']:.4f}")
    print(f"–£—Å–∫–æ—Ä–µ–Ω–∏–µ: {results['RandomForest_CPU']['training_time'] / results[best_model_name]['training_time']:.2f}x")

if __name__ == "__main__":
    main()

